wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jincan333. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /research/cbim/vast/cj574/LLaMA-Factory/wandb/run-20250101_124552-n1n7wmyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048_eval
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jincan333/safe_reason
wandb: üöÄ View run at https://wandb.ai/jincan333/safe_reason/runs/n1n7wmyo
2025-01-01:12:45:53,286 INFO     [__main__.py:279] Verbosity set to INFO
2025-01-01:12:45:59,900 INFO     [__main__.py:376] Selected Tasks: ['gsm8k']
2025-01-01:12:45:59,903 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-01-01:12:45:59,904 WARNING  [evaluator.py:175] generation_kwargs specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-01-01:12:45:59,904 INFO     [evaluator.py:201] Initializing vllm model, with arguments: {'pretrained': '/research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048', 'tensor_parallel_size': 1, 'dtype': 'auto'}
INFO 01-01 12:46:05 config.py:510] This model supports multiple tasks: {'score', 'generate', 'embed', 'reward', 'classify'}. Defaulting to 'generate'.
INFO 01-01 12:46:05 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='/research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048', speculative_config=None, tokenizer='/research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=/research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 01-01 12:46:07 selector.py:120] Using Flash Attention backend.
INFO 01-01 12:46:07 model_runner.py:1094] Starting to load model /research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.64it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.38it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.31it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.67it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]

INFO 01-01 12:46:10 model_runner.py:1099] Loading model weights took 14.9595 GB
INFO 01-01 12:46:11 worker.py:241] Memory profiling takes 1.47 seconds
INFO 01-01 12:46:11 worker.py:241] the current vLLM instance can use total_gpu_memory (44.45GiB) x gpu_memory_utilization (0.90) = 40.00GiB
INFO 01-01 12:46:11 worker.py:241] model weights take 14.96GiB; non_torch_memory takes 0.07GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 23.74GiB.
INFO 01-01 12:46:12 gpu_executor.py:76] # GPU blocks: 12156, # CPU blocks: 2048
INFO 01-01 12:46:12 gpu_executor.py:80] Maximum concurrency for 8192 tokens per request: 23.74x
INFO 01-01 12:46:14 model_runner.py:1415] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|‚ñé         | 1/35 [00:00<00:16,  2.03it/s]Capturing CUDA graph shapes:   6%|‚ñå         | 2/35 [00:00<00:16,  2.04it/s]Capturing CUDA graph shapes:   9%|‚ñä         | 3/35 [00:01<00:16,  1.99it/s]Capturing CUDA graph shapes:  11%|‚ñà‚ñè        | 4/35 [00:02<00:15,  1.98it/s]Capturing CUDA graph shapes:  14%|‚ñà‚ñç        | 5/35 [00:02<00:14,  2.00it/s]Capturing CUDA graph shapes:  17%|‚ñà‚ñã        | 6/35 [00:03<00:14,  1.99it/s]Capturing CUDA graph shapes:  20%|‚ñà‚ñà        | 7/35 [00:03<00:14,  1.97it/s]Capturing CUDA graph shapes:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:04<00:13,  1.96it/s]Capturing CUDA graph shapes:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:04<00:13,  1.94it/s]Capturing CUDA graph shapes:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:05<00:12,  1.94it/s]Capturing CUDA graph shapes:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:05<00:12,  1.95it/s]Capturing CUDA graph shapes:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:06<00:11,  1.96it/s]Capturing CUDA graph shapes:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:07<00:10,  1.99it/s]Capturing CUDA graph shapes:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:07<00:09,  2.01it/s]Capturing CUDA graph shapes:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:08<00:09,  1.98it/s]Capturing CUDA graph shapes:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:08<00:09,  1.99it/s]Capturing CUDA graph shapes:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:09<00:08,  2.00it/s]Capturing CUDA graph shapes:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:09<00:07,  2.02it/s]Capturing CUDA graph shapes:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:10<00:07,  1.99it/s]Capturing CUDA graph shapes:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:11<00:06,  2.03it/s]Capturing CUDA graph shapes:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:11<00:05,  2.07it/s]Capturing CUDA graph shapes:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:11<00:05,  2.11it/s]Capturing CUDA graph shapes:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:12<00:04,  2.15it/s]Capturing CUDA graph shapes:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:12<00:04,  2.18it/s]Capturing CUDA graph shapes:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:13<00:03,  2.21it/s]Capturing CUDA graph shapes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:13<00:03,  2.20it/s]Capturing CUDA graph shapes:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:14<00:02,  2.20it/s]Capturing CUDA graph shapes:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:14<00:02,  2.23it/s]Capturing CUDA graph shapes:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:15<00:01,  2.23it/s]Capturing CUDA graph shapes:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:15<00:01,  2.24it/s]Capturing CUDA graph shapes:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:15<00:00,  2.25it/s]Capturing CUDA graph shapes:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:16<00:00,  2.24it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:16<00:00,  2.26it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:16<00:00,  2.08it/s]
INFO 01-01 12:46:31 model_runner.py:1535] Graph capturing finished in 17 secs, took 0.26 GiB
INFO 01-01 12:46:31 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 21.17 seconds
2025-01-01:12:46:34,500 WARNING  [evaluator.py:270] Overwriting default num_fewshot of gsm8k from 5 to 5
2025-01-01:12:46:34,501 WARNING  [evaluator.py:406] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-01-01:12:46:34,501 INFO     [task.py:415] Building contexts for gsm8k on rank 0...
  0%|          | 0/1319 [00:00<?, ?it/s]  3%|‚ñé         | 39/1319 [00:00<00:03, 385.84it/s]  6%|‚ñå         | 80/1319 [00:00<00:03, 395.25it/s]  9%|‚ñâ         | 121/1319 [00:00<00:02, 399.71it/s] 12%|‚ñà‚ñè        | 162/1319 [00:00<00:02, 401.59it/s] 15%|‚ñà‚ñå        | 203/1319 [00:00<00:02, 402.59it/s] 18%|‚ñà‚ñä        | 244/1319 [00:00<00:02, 402.42it/s] 22%|‚ñà‚ñà‚ñè       | 285/1319 [00:00<00:02, 403.08it/s] 25%|‚ñà‚ñà‚ñç       | 326/1319 [00:00<00:02, 403.77it/s] 28%|‚ñà‚ñà‚ñä       | 367/1319 [00:00<00:02, 403.65it/s] 31%|‚ñà‚ñà‚ñà       | 408/1319 [00:01<00:02, 403.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 449/1319 [00:01<00:02, 403.05it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 490/1319 [00:01<00:02, 403.49it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 531/1319 [00:01<00:01, 402.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 572/1319 [00:01<00:01, 402.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 613/1319 [00:01<00:01, 401.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 654/1319 [00:01<00:01, 401.07it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 695/1319 [00:01<00:01, 400.83it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 736/1319 [00:01<00:01, 400.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 777/1319 [00:01<00:01, 400.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 818/1319 [00:02<00:01, 400.99it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 859/1319 [00:02<00:01, 401.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 900/1319 [00:02<00:01, 402.27it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 941/1319 [00:02<00:00, 402.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 982/1319 [00:02<00:00, 402.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1023/1319 [00:02<00:00, 402.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1064/1319 [00:02<00:00, 402.21it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1105/1319 [00:02<00:00, 401.43it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1146/1319 [00:02<00:00, 401.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1187/1319 [00:02<00:00, 401.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1228/1319 [00:03<00:00, 401.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1269/1319 [00:03<00:00, 402.24it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1310/1319 [00:03<00:00, 403.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [00:03<00:00, 401.86it/s]
2025-01-01:12:46:37,802 INFO     [evaluator_utils.py:196] Task: ConfigurableTask(task_name=gsm8k,output_type=generate_until,num_fewshot=5,num_samples=1319); document 0; context prompt (starting on next line):    
<|begin_of_text|><|start_header_id|>user<|end_header_id|>

Question: Steve finds 100 gold bars while visiting Oregon. He wants to distribute his gold bars evenly to his 4 friends. If 20 gold bars were lost on the way back to San Diego, how many gold bars will each of his 4 friends get when he returns?
Answer: He only has 100 - 20 = <<100-20=80>>80 gold bars after losing 20 of them.
He then gives each of his friends 80 √∑ 4 = <<80/4=20>>20 gold bars.
#### 20

Question: In a week, Mortdecai collects 8 dozen  eggs every Tuesday and Thursday, and he delivers 3 dozen  eggs to the market and 5 dozen eggs to the mall. He then uses 4 dozen eggs to make a pie every Saturday. Mortdecai donates the remaining eggs to the charity by Sunday. How many  eggs does he donate to the charity?
Answer: Mortdecai collects a total of 8x2 = <<8*2=16>>16 dozens of eggs.
He sells a total of 3 + 5 = <<3+5=8>>8 dozens of eggs.
So, 16 - 8 = <<16-8=8>>8 dozens of eggs are left.
After using 4 dozens of eggs to make a pie, 8 - 4 = <<8-4=4>>4 dozens of eggs are left.
Since there are 12 in 1 dozen, then Mortdecai donates 4 x 12 = <<4*12=48>>48 pieces of eggs to the charity.
#### 48

Question: Corey downloaded two movie series from his Netflix account with 12 and 14 seasons per series, respectively. However, in the week, his computer got a mechanical failure, and he lost two episodes from each season for both series. If each season in the movie series that Corey downloaded had 16 episodes, how many episodes remained after the computer's mechanical failure?
Answer: In the first movie series with 12 seasons, after the mechanical failure, the number of episodes that Corey lost is 2*12 = <<2*12=24>>24
Originally, the movie series with 12 seasons had 12*16 = <<12*16=192>>192 episodes.
After the mechanical failure, Corey had 192-24 = <<192-24=168>>168 episodes remaining in the first movie series.
Similarly, the 14 season movie series also had 14*2 = <<14*2=28>>28 lost after the computer's mechanical failure.
Originally, the movie series with 14 seasons has 14*16 = <<14*16=224>>224 episodes.
The mechanical failure of the computer reduced the number of episodes in the 14 season movie series to 224-28 = <<224-28=196>>196
After the loss, Corey had 196+168 = <<196+168=364>>364 episodes remaining from the two movie series he had downloaded.
#### 364

Question: There were 18 students assigned in a minibus for a field trip. Eight of these students were boys. On the day of the field trip, the number of girls and boys was the same since some of the girls were not able to join the trip. How many girls were not able to join the field trip?
Answer: 8 boys + 8 girls = <<8+8=16>>16 students joined the field trip.
Thus, 18 - 16 = <<18-16=2>>2 girls were not able to join the field trip.
#### 2

Question: There are 200 more red apples than green apples in a grocery store. A truck arrives and delivers another 340 green apples. If there were originally 32 green apples, how many more green apples than red apples are there in the store now?
Answer: There are 200 + 32 = <<200+32=232>>232 red apples.
After the delivery there are 340 + 32 = <<340+32=372>>372 green apples
There are now 372 - 232 = <<372-232=140>>140 more green apples than red apples now.
#### 140

Question: Janet‚Äôs ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?
Answer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>


(end of prompt on previous line)
target string or answer choice index (starting on next line):
Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.
She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer‚Äôs market.
#### 18
(end of target on previous line)
2025-01-01:12:46:37,802 INFO     [evaluator_utils.py:200] Request: Instance(request_type='generate_until', doc={'question': "Janet‚Äôs ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?", 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer‚Äôs market.\n#### 18'}, arguments=("<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Steve finds 100 gold bars while visiting Oregon. He wants to distribute his gold bars evenly to his 4 friends. If 20 gold bars were lost on the way back to San Diego, how many gold bars will each of his 4 friends get when he returns?\nAnswer: He only has 100 - 20 = <<100-20=80>>80 gold bars after losing 20 of them.\nHe then gives each of his friends 80 √∑ 4 = <<80/4=20>>20 gold bars.\n#### 20\n\nQuestion: In a week, Mortdecai collects 8 dozen  eggs every Tuesday and Thursday, and he delivers 3 dozen  eggs to the market and 5 dozen eggs to the mall. He then uses 4 dozen eggs to make a pie every Saturday. Mortdecai donates the remaining eggs to the charity by Sunday. How many  eggs does he donate to the charity?\nAnswer: Mortdecai collects a total of 8x2 = <<8*2=16>>16 dozens of eggs.\nHe sells a total of 3 + 5 = <<3+5=8>>8 dozens of eggs.\nSo, 16 - 8 = <<16-8=8>>8 dozens of eggs are left.\nAfter using 4 dozens of eggs to make a pie, 8 - 4 = <<8-4=4>>4 dozens of eggs are left.\nSince there are 12 in 1 dozen, then Mortdecai donates 4 x 12 = <<4*12=48>>48 pieces of eggs to the charity.\n#### 48\n\nQuestion: Corey downloaded two movie series from his Netflix account with 12 and 14 seasons per series, respectively. However, in the week, his computer got a mechanical failure, and he lost two episodes from each season for both series. If each season in the movie series that Corey downloaded had 16 episodes, how many episodes remained after the computer's mechanical failure?\nAnswer: In the first movie series with 12 seasons, after the mechanical failure, the number of episodes that Corey lost is 2*12 = <<2*12=24>>24\nOriginally, the movie series with 12 seasons had 12*16 = <<12*16=192>>192 episodes.\nAfter the mechanical failure, Corey had 192-24 = <<192-24=168>>168 episodes remaining in the first movie series.\nSimilarly, the 14 season movie series also had 14*2 = <<14*2=28>>28 lost after the computer's mechanical failure.\nOriginally, the movie series with 14 seasons has 14*16 = <<14*16=224>>224 episodes.\nThe mechanical failure of the computer reduced the number of episodes in the 14 season movie series to 224-28 = <<224-28=196>>196\nAfter the loss, Corey had 196+168 = <<196+168=364>>364 episodes remaining from the two movie series he had downloaded.\n#### 364\n\nQuestion: There were 18 students assigned in a minibus for a field trip. Eight of these students were boys. On the day of the field trip, the number of girls and boys was the same since some of the girls were not able to join the trip. How many girls were not able to join the field trip?\nAnswer: 8 boys + 8 girls = <<8+8=16>>16 students joined the field trip.\nThus, 18 - 16 = <<18-16=2>>2 girls were not able to join the field trip.\n#### 2\n\nQuestion: There are 200 more red apples than green apples in a grocery store. A truck arrives and delivers another 340 green apples. If there were originally 32 green apples, how many more green apples than red apples are there in the store now?\nAnswer: There are 200 + 32 = <<200+32=232>>232 red apples.\nAfter the delivery there are 340 + 32 = <<340+32=372>>372 green apples\nThere are now 372 - 232 = <<372-232=140>>140 more green apples than red apples now.\n#### 140\n\nQuestion: Janet‚Äôs ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\nAnswer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", {'until': ['Question:', '</s>', '<|im_end|>'], 'do_sample': False, 'temperature': 0, 'top_p': 1}), idx=0, metadata=('gsm8k', 0, 1), resps=[], filtered_resps={}, task_name='gsm8k', doc_id=0, repeats=1)
2025-01-01:12:46:37,803 INFO     [evaluator.py:496] Running generate_until requests
Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/1319 [00:19<7:06:23, 19.41s/it]Running generate_until requests:   5%|‚ñç         | 65/1319 [00:37<10:16,  2.03it/s] Running generate_until requests:  10%|‚ñâ         | 129/1319 [00:55<07:20,  2.70it/s]Running generate_until requests:  15%|‚ñà‚ñç        | 193/1319 [01:13<06:12,  3.03it/s]Running generate_until requests:  19%|‚ñà‚ñâ        | 257/1319 [01:30<05:21,  3.30it/s]Running generate_until requests:  24%|‚ñà‚ñà‚ñç       | 321/1319 [01:48<04:53,  3.40it/s]Running generate_until requests:  29%|‚ñà‚ñà‚ñâ       | 385/1319 [02:05<04:26,  3.51it/s]Running generate_until requests:  34%|‚ñà‚ñà‚ñà‚ñç      | 449/1319 [02:22<04:02,  3.58it/s]Running generate_until requests:  39%|‚ñà‚ñà‚ñà‚ñâ      | 513/1319 [02:38<03:39,  3.68it/s]Running generate_until requests:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 577/1319 [02:54<03:15,  3.79it/s]Running generate_until requests:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 641/1319 [03:11<02:57,  3.81it/s]Running generate_until requests:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 705/1319 [03:27<02:39,  3.84it/s]Running generate_until requests:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 769/1319 [03:44<02:22,  3.85it/s]Running generate_until requests:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 833/1319 [04:00<02:05,  3.88it/s]Running generate_until requests:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 897/1319 [04:15<01:46,  3.95it/s]Running generate_until requests:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 961/1319 [04:31<01:29,  3.98it/s]Running generate_until requests:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1025/1319 [04:47<01:13,  4.02it/s]Running generate_until requests:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1089/1319 [05:02<00:56,  4.07it/s]Running generate_until requests:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1153/1319 [05:17<00:40,  4.13it/s]Running generate_until requests:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1217/1319 [05:32<00:24,  4.21it/s]Running generate_until requests:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1281/1319 [05:41<00:07,  4.77it/s]Running generate_until requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [05:41<00:00,  3.87it/s]
2025-01-01:12:52:26,780 INFO     [evaluation_tracker.py:206] Saving results aggregated
2025-01-01:12:52:26,787 INFO     [evaluation_tracker.py:287] Saving per-sample results for: gsm8k
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:        gsm8k/exact_match,flexible-extract ‚ñÅ
wandb:            gsm8k/exact_match,strict-match ‚ñÅ
wandb: gsm8k/exact_match_stderr,flexible-extract ‚ñÅ
wandb:     gsm8k/exact_match_stderr,strict-match ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                               gsm8k/alias gsm8k
wandb:        gsm8k/exact_match,flexible-extract 0.66187
wandb:            gsm8k/exact_match,strict-match 0.66414
wandb: gsm8k/exact_match_stderr,flexible-extract 0.01303
wandb:     gsm8k/exact_match_stderr,strict-match 0.01301
wandb: 
wandb: üöÄ View run llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048_eval at: https://wandb.ai/jincan333/safe_reason/runs/n1n7wmyo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/jincan333/safe_reason
wandb: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20250101_124552-n1n7wmyo/logs
vllm (pretrained=/research/cbim/medical/cj574/safe_reason/llama3_sft_gsm8k_tbs16_ebs16_lr1e-6_cl2048,tensor_parallel_size=1,dtype=auto), gen_kwargs: (top_p=1,temperature=0), limit: None, num_fewshot: 5, batch_size: 64
|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|
|gsm8k|      3|flexible-extract|     5|exact_match|‚Üë  |0.6619|¬±  | 0.013|
|     |       |strict-match    |     5|exact_match|‚Üë  |0.6641|¬±  | 0.013|

[rank0]:[W101 12:52:30.779046336 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
