Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 60 examples [00:00, 5778.47 examples/s]
num_proc must be <= 60. Reducing num_proc to 60 for dataset of size 60.
Parameter 'function'=<function personalized_generate.<locals>.<lambda> at 0x70ab8b93b740> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map (num_proc=60):   0%|          | 0/60 [00:00<?, ? examples/s]Map (num_proc=60):   2%|▏         | 1/60 [00:01<01:19,  1.34s/ examples]Map (num_proc=60):  17%|█▋        | 10/60 [00:01<00:05,  9.12 examples/s]Map (num_proc=60):  30%|███       | 18/60 [00:01<00:02, 17.16 examples/s]Map (num_proc=60):  48%|████▊     | 29/60 [00:01<00:01, 29.98 examples/s]Map (num_proc=60):  62%|██████▏   | 37/60 [00:01<00:00, 35.71 examples/s]Map (num_proc=60):  73%|███████▎  | 44/60 [00:02<00:00, 37.06 examples/s]Map (num_proc=60):  83%|████████▎ | 50/60 [00:02<00:00, 33.30 examples/s]Map (num_proc=60):  92%|█████████▏| 55/60 [00:04<00:00,  6.66 examples/s]Map (num_proc=60):  98%|█████████▊| 59/60 [00:10<00:00,  2.46 examples/s]Map (num_proc=60): 100%|██████████| 60/60 [00:14<00:00,  4.28 examples/s]
num_proc must be <= 60. Reducing num_proc to 60 for dataset of size 60.
Map (num_proc=60):   0%|          | 0/60 [00:00<?, ? examples/s]Map (num_proc=60):   8%|▊         | 5/60 [00:00<00:01, 48.35 examples/s]Map (num_proc=60): 100%|██████████| 60/60 [00:00<00:00, 222.10 examples/s]
Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 409.44ba/s]
dict_keys(['string_matching', 'openai_moderation_api', 'pair', 'gpt4_judge', 'jailbroken_binary', 'category_binary', 'strongreject_rubric', 'strongreject_finetuned', 'strongreject_aisi', 'harmbench'])
num_proc must be <= 60. Reducing num_proc to 60 for dataset of size 60.
Map (num_proc=60):   0%|          | 0/60 [00:00<?, ? examples/s]Map (num_proc=60):   2%|▏         | 1/60 [00:02<01:59,  2.02s/ examples]Map (num_proc=60):   7%|▋         | 4/60 [00:02<00:24,  2.32 examples/s]Map (num_proc=60):  12%|█▏        | 7/60 [00:02<00:11,  4.58 examples/s]Map (num_proc=60):  18%|█▊        | 11/60 [00:02<00:06,  8.15 examples/s]Map (num_proc=60):  23%|██▎       | 14/60 [00:02<00:04, 10.51 examples/s]Map (num_proc=60):  30%|███       | 18/60 [00:02<00:03, 13.21 examples/s]Map (num_proc=60):  45%|████▌     | 27/60 [00:02<00:01, 23.41 examples/s]Map (num_proc=60):  57%|█████▋    | 34/60 [00:02<00:00, 31.22 examples/s]Map (num_proc=60):  65%|██████▌   | 39/60 [00:03<00:00, 28.38 examples/s]Map (num_proc=60):  72%|███████▏  | 43/60 [00:03<00:00, 24.08 examples/s]Map (num_proc=60):  78%|███████▊  | 47/60 [00:03<00:00, 26.29 examples/s]Map (num_proc=60):  85%|████████▌ | 51/60 [00:03<00:00, 23.46 examples/s]Map (num_proc=60):  90%|█████████ | 54/60 [00:03<00:00, 22.40 examples/s]Map (num_proc=60):  95%|█████████▌| 57/60 [00:04<00:00, 12.25 examples/s]Map (num_proc=60):  98%|█████████▊| 59/60 [00:07<00:00,  2.67 examples/s]Map (num_proc=60): 100%|██████████| 60/60 [00:09<00:00,  6.67 examples/s]
Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 385.08ba/s]
jailbreak
happy_to_help    0.033333
Name: score, dtype: float64
