{
    "model": "/research/cbim/medical/cj574/safe_reason/llama3_sft_sr_sft_preliminary_meta-llama-Meta-Llama-3-8B-Instruct_5_5_50_500_0_tbs8_ebs8_gas2_lr5e-6_cl4096",
    "judge_model": "gpt-4o-mini-2024-07-18",
    "dataset": "xstest",
    "jailbreak": "none",
    "cot_prompt": "none",
    "evaluator": "strongreject_rubric",
    "temperature": 0.0,
    "top_p": 1.0,
    "max_length": 4096,
    "generate": true,
    "evaluate": true,
    "gpu": "cuda:0"
}
loading dataset xstest and applying jailbreak none
dict_keys(['auto_payload_splitting', 'auto_obfuscation', 'rot_13', 'disemvowel', 'pair', 'pap_evidence_based_persuasion', 'pap_expert_endorsement', 'pap_misrepresentation', 'pap_authority_endorsement', 'pap_logical_appeal', 'translation_hmong', 'translation_scotts_gaelic', 'translation_guarani', 'translation_zulu', 'gcg_transfer_harmbench', 'gcg_transfer_universal_attacks', 'combination_3', 'combination_2', 'few_shot_json', 'dev_mode_v2', 'dev_mode_with_rant', 'wikipedia_with_title', 'distractors', 'wikipedia', 'style_injection_json', 'style_injection_short', 'refusal_suppression', 'prefix_injection', 'distractors_negated', 'poems', 'base64', 'base64_raw', 'base64_input_only', 'base64_output_only', 'none', 'evil_confidant', 'aim'])
Traceback (most recent call last):
  File "/research/cbim/vast/cj574/LLaMA-Factory/safe_reason/evaluate.py", line 181, in <module>
    generate_model = LLM(model=args.model, max_num_seqs=64, tensor_parallel_size=1, max_model_len=args.max_length)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/utils.py", line 986, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/entrypoints/llm.py", line 230, in __init__
    self.llm_engine = self.engine_class.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/engine/llm_engine.py", line 514, in from_engine_args
    engine_config = engine_args.create_engine_config(usage_context)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 1044, in create_engine_config
    model_config = self.create_model_config()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 970, in create_model_config
    return ModelConfig(
           ^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/config.py", line 276, in __init__
    hf_config = get_config(self.model, trust_remote_code, revision,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/vllm/transformers_utils/config.py", line 190, in get_config
    file_exists(model,
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/research/cbim/vast/cj574/miniforge3/envs/llamafactory/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/research/cbim/medical/cj574/safe_reason/llama3_sft_sr_sft_preliminary_meta-llama-Meta-Llama-3-8B-Instruct_5_5_50_500_0_tbs8_ebs8_gas2_lr5e-6_cl4096'. Use `repo_type` argument if needed.
